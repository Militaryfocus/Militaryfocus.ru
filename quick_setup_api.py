#!/usr/bin/env python3
"""
–ë—ã—Å—Ç—Ä–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ API –∫–ª—é—á–µ–π —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
"""

import os
import json
from pathlib import Path

def create_env_template():
    """–°–æ–∑–¥–∞–µ—Ç —à–∞–±–ª–æ–Ω .env —Ñ–∞–π–ª–∞"""
    env_content = """# API –∫–ª—é—á–∏ –¥–ª—è –ò–ò —Å–µ—Ä–≤–∏—Å–æ–≤
# –ü–æ–ª—É—á–∏—Ç–µ –∫–ª—é—á–∏ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Å–∞–π—Ç–∞—Ö:
# OpenAI: https://platform.openai.com/api-keys
# Anthropic: https://console.anthropic.com/
# Google: https://makersuite.google.com/app/apikey

# OpenAI
OPENAI_API_KEY=sk-your-openai-key-here

# Anthropic
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Google Gemini
GOOGLE_API_KEY=AI-your-google-key-here

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
AI_MODEL_OPENAI=gpt-4
AI_MODEL_ANTHROPIC=claude-3-sonnet-20240229
AI_MODEL_GOOGLE=gemini-pro

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω—ã)
LOCAL_MODELS_ENABLED=true
AI_DEVICE=cpu
AI_CACHE_ENABLED=true
"""
    
    with open('.env.template', 'w', encoding='utf-8') as f:
        f.write(env_content)
    
    print("üìù –°–æ–∑–¥–∞–Ω —à–∞–±–ª–æ–Ω .env.template")
    print("   –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –µ–≥–æ –≤ .env –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ –≤–∞—à–∏ –∫–ª—é—á–∏")

def load_env_config():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    config = {
        "ai_providers": {
            "openai": {
                "enabled": bool(os.getenv('OPENAI_API_KEY')),
                "api_key": os.getenv('OPENAI_API_KEY', ''),
                "model": os.getenv('AI_MODEL_OPENAI', 'gpt-4'),
                "max_tokens": 2000,
                "temperature": 0.7,
                "timeout": 30
            },
            "anthropic": {
                "enabled": bool(os.getenv('ANTHROPIC_API_KEY')),
                "api_key": os.getenv('ANTHROPIC_API_KEY', ''),
                "model": os.getenv('AI_MODEL_ANTHROPIC', 'claude-3-sonnet-20240229'),
                "max_tokens": 2000,
                "temperature": 0.7,
                "timeout": 30
            },
            "google": {
                "enabled": bool(os.getenv('GOOGLE_API_KEY')),
                "api_key": os.getenv('GOOGLE_API_KEY', ''),
                "model": os.getenv('AI_MODEL_GOOGLE', 'gemini-pro'),
                "max_tokens": 2000,
                "temperature": 0.7,
                "timeout": 30
            },
            "local": {
                "enabled": os.getenv('LOCAL_MODELS_ENABLED', 'true').lower() == 'true',
                "models": {
                    "text_generation": "microsoft/DialoGPT-medium",
                    "sentiment_analysis": "cardiffnlp/twitter-roberta-base-sentiment-latest",
                    "summarization": "facebook/bart-large-cnn"
                },
                "device": os.getenv('AI_DEVICE', 'cpu'),
                "cache_enabled": os.getenv('AI_CACHE_ENABLED', 'true').lower() == 'true'
            }
        },
        "cache": {
            "enabled": True,
            "ttl": 3600,
            "max_size": 1000,
            "storage_path": "./cache"
        },
        "rate_limiting": {
            "enabled": True,
            "requests_per_minute": 60,
            "requests_per_hour": 1000
        },
        "monitoring": {
            "enabled": True,
            "log_level": "INFO",
            "metrics_enabled": True,
            "alert_threshold": 0.8
        },
        "security": {
            "encrypt_keys": True,
            "key_rotation_days": 90,
            "audit_logging": True
        }
    }
    
    return config

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîë –ë—ã—Å—Ç—Ä–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ API –∫–ª—é—á–µ–π")
    print("=" * 40)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ .env —Ñ–∞–π–ª–∞
    env_file = Path('.env')
    if not env_file.exists():
        print("‚ö†Ô∏è –§–∞–π–ª .env –Ω–µ –Ω–∞–π–¥–µ–Ω")
        create_env_template()
        print("\nüìã –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:")
        print("1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ .env.template –≤ .env")
        print("2. –ó–∞–ø–æ–ª–Ω–∏—Ç–µ –≤–∞—à–∏ API –∫–ª—é—á–∏")
        print("3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç —Å–Ω–æ–≤–∞")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    config = load_env_config()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ ai_config.json
    with open('ai_config.json', 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å
    print("\nüìä –°—Ç–∞—Ç—É—Å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤:")
    for provider, settings in config['ai_providers'].items():
        if provider == 'local':
            status = "‚úÖ –í–∫–ª—é—á–µ–Ω" if settings.get('enabled', False) else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω"
            print(f"  {provider}: {status}")
        else:
            status = "‚úÖ –ù–∞—Å—Ç—Ä–æ–µ–Ω" if settings.get('enabled', False) else "‚ùå –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
            print(f"  {provider}: {status}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...")
    try:
        import sys
        sys.path.append('blog')
        
        from blog.ai_provider_manager import AIProviderManager
        provider_manager = AIProviderManager()
        print("‚úÖ AIProviderManager —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
        print("\nüéâ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print("üöÄ –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ò–ò —Å–µ—Ä–≤–∏—Å—ã")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π")

if __name__ == '__main__':
    main()